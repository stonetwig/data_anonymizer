#!/usr/bin/env python3
"""
CSV Anonymizer Script

This script reads the out.csv file generated by combine_csv.py and anonymizes all data values 
using SHA256 hashing. The column headers are preserved, but all data values are replaced with 
their SHA256 hash equivalents.

Hashing algorithm: hashlib.sha256(value.strip().lower().encode()).hexdigest()

Configuration:
    INPUT_FILE: The CSV file to anonymize (default: out.csv)
    OUTPUT_FILE: The anonymized output file (default: out_anonymized.csv)
"""

# CONFIGURATION
INPUT_FILE = "/home/markus/Documents/leaks/miljodata/out.csv"
OUTPUT_FILE = "out_anonymized.csv"

# Hash configuration for efficient anonymization
HASH_LENGTH = 16  # Use first 16 chars of hash (reduces collision risk while saving space)
USE_MAPPING_TABLE = True  # Create a separate mapping file for reversible anonymization

import csv
import hashlib
import os
import sys


def anonymize_value(value: str, mapping_table: dict = None) -> str:
    """
    Anonymize a single value using truncated SHA256 hashing.
    
    Args:
        value: The original value to anonymize
        mapping_table: Optional dict to store original->hash mappings
        
    Returns:
        Truncated SHA256 hash of the processed value
    """
    if not value or value.strip() == "":
        return ""  # Keep empty values as empty
    
    # Apply the specified hashing algorithm
    processed_value = value.strip().lower()
    hash_object = hashlib.sha256(processed_value.encode())
    full_hash = hash_object.hexdigest()
    truncated_hash = full_hash[:HASH_LENGTH]
    
    # Store mapping if table provided
    if mapping_table is not None:
        mapping_table[truncated_hash] = processed_value
    
    return truncated_hash


def anonymize_csv():
    """
    Read the input CSV file and create an anonymized version.
    All data values are replaced with SHA256 hashes while preserving the structure.
    """
    
    # Check if input file exists
    if not os.path.exists(INPUT_FILE):
        print(f"Error: Input file '{INPUT_FILE}' does not exist.")
        print("Make sure to run combine_csv.py first to generate out.csv")
        sys.exit(1)
    
    # Delete existing output file if it exists
    if os.path.exists(OUTPUT_FILE):
        os.remove(OUTPUT_FILE)
        print(f"Deleted existing {OUTPUT_FILE}")
    
    print(f"Reading from: {INPUT_FILE}")
    print(f"Writing to: {OUTPUT_FILE}")
    print("=" * 50)
    
    anonymized_rows = []
    original_headers = []
    total_values_processed = 0
    mapping_table = {} if USE_MAPPING_TABLE else None
    
    try:
        # Read the input CSV
        with open(INPUT_FILE, 'r', encoding='utf-8', newline='') as infile:
            reader = csv.DictReader(infile)
            original_headers = reader.fieldnames
            
            if not original_headers:
                print("Error: No headers found in the input file.")
                sys.exit(1)
            
            print(f"Found {len(original_headers)} columns:")
            for header in original_headers:
                print(f"  - {header}")
            
            print(f"\nAnonymizing data...")
            
            # Process each row
            for row_num, row in enumerate(reader, 1):
                anonymized_row = {}
                
                # Anonymize each value in the row
                for header in original_headers:
                    original_value = row.get(header, "")
                    anonymized_value = anonymize_value(original_value, mapping_table)
                    anonymized_row[header] = anonymized_value
                    
                    if original_value.strip():  # Count non-empty values
                        total_values_processed += 1
                
                anonymized_rows.append(anonymized_row)
                
                # Show progress for large files
                if row_num % 1000 == 0:
                    print(f"  Processed {row_num} rows...")
            
            print(f"  Processed {row_num} total rows")
        
        # Write the anonymized CSV
        with open(OUTPUT_FILE, 'w', encoding='utf-8', newline='') as outfile:
            writer = csv.DictWriter(outfile, fieldnames=original_headers)
            writer.writeheader()
            writer.writerows(anonymized_rows)
        
        # Save mapping table if enabled
        if USE_MAPPING_TABLE and mapping_table:
            mapping_file = OUTPUT_FILE.replace('.csv', '_mapping.json')
            import json
            with open(mapping_file, 'w', encoding='utf-8') as mapfile:
                json.dump(mapping_table, mapfile, indent=2)
            print(f"Mapping table saved as: {mapping_file}")
        
        print(f"\nAnonymization completed successfully!")
        print(f"Total values anonymized: {total_values_processed}")
        print(f"Unique values in mapping: {len(mapping_table) if mapping_table else 'N/A'}")
        print(f"Output saved as: {OUTPUT_FILE}")
        print(f"Hash length: {HASH_LENGTH} characters (vs 64 for full SHA256)")
        
        # Show a preview of the anonymized data
        print(f"\nPreview of anonymized data (first 3 rows):")
        print("Columns:", ", ".join(original_headers))
        
        for i, row in enumerate(anonymized_rows[:3]):
            values = [row.get(col, "") for col in original_headers]
            print(f"Row {i+1}: {values}")
            
    except Exception as e:
        print(f"Error processing CSV file: {e}")
        sys.exit(1)


def main():
    """Main function to run the anonymization process."""
    
    print("CSV Data Anonymizer")
    print("=" * 20)
    
    try:
        anonymize_csv()
    except KeyboardInterrupt:
        print("\nOperation cancelled by user.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()
